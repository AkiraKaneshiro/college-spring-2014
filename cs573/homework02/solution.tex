\documentclass{article}

\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{extramarks}
\usepackage[usenames,dvipsnames]{color}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{changepage}
\usepackage{lineno}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{hyperref}
\usepackage{tikz}
\usepackage{listings}
\usepackage{graphics}
\usepackage{subcaption}
\usepackage{float}
\usepackage{fancyvrb}

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\lhead{\hmwkAuthorName}
\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle}
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength{\floatsep}{100pt}
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\algrenewcomment[1]{\hfill // #1}

\setlength\parindent{0pt}

\hypersetup{colorlinks=true}

\newcommand{\enterProblemHeader}[1]{
    \nobreak\extramarks{}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
}

\newcommand{\exitProblemHeader}[1]{
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \stepcounter{#1}
    \nobreak\extramarks{Problem \arabic{#1}}{}\nobreak{}
}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}
\newcounter{homeworkProblemCounter}
\setcounter{homeworkProblemCounter}{1}
\nobreak\extramarks{Problem \arabic{homeworkProblemCounter}}{}\nobreak{}

\newenvironment{homeworkProblem}{
    \section{Problem \arabic{homeworkProblemCounter}}
    \setcounter{partCounter}{1}
    \enterProblemHeader{homeworkProblemCounter}
}{
    \exitProblemHeader{homeworkProblemCounter}
}

\newcommand{\hmwkTitle}{Homework\ \#2}
\newcommand{\hmwkDueDate}{February 28, 2014}
\newcommand{\hmwkClass}{ComS 573}
\newcommand{\hmwkClassTime}{10am}
\newcommand{\hmwkClassInstructor}{Professor De Brabanter}
\newcommand{\hmwkAuthorName}{Josh Davis}

\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
    \vspace{0.1in}\large{\textit{\hmwkClassInstructor\ at\ \hmwkClassTime}}
    \vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}
\date{}

\newcommand{\alg}[1]{\textsc{\bfseries \footnotesize #1}}
\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}
\newcommand{\dx}{\mathrm{d}x}
\newcommand{\solution}{\textbf{\large Solution}}

\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Bias}{\mathrm{Bias}}
\newcommand{\dist}[1]{\sim \mathrm{#1}}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

\begin{document}

\maketitle

\pagebreak

\begin{homeworkProblem}
    Using a created simulated data, answer the questions regarding simple
    linear regression.
    \\

    \part

    Write out the form of the linear model. What are the regression
    coefficients?
    \\

    \solution

    Solution
    \\

    \part

    What is the correlation between \(x1\) and \(x2\)? Create a scatterplot
    displaying the relationship between the variables.
    \\

    \solution

    Solution.
    \\

    \part

    Using the data, fit a least squares regression to predict \(Y\) using
    \(x1\) and \(x2\). Describe the results obtained. What are
    \(\hat{\beta_0}\) and \(\hat{\beta_1}\), and \(\hat{\beta_2}\)? How do
    these relate to the true \(\beta_0\), \(\beta_1\), \(\beta_2\)? Can you
    reject the null hypothesis \(H_0 : \beta_1 = 0\)? How about \(H_0 : \beta_2
    = 0\)?
    \\

    \solution

    Solution.
    \\

    \part

    Now fit a least squares regression to predict \(Y\) using only \(x1\).
    Comment on your results. Can you reject the null hypothesis \(H_0 : \beta_1
    = 0\)?
    \\

    \solution

    Solution.
    \\\

    \part

    Now fit a least squares regression to predict \(Y\) using only \(x2\).
    Comment on your results. Can you reject the null hypothesis \(H_0 : \beta_1
    = 0\)?
    \\

    \part

    Do the results obtained in c-e contradict each other? Explain your answer.
    \\

    \solution

    Solution.
    \\

    \part

    Now suppose we obtain one additional observation, which was unfortunately
    mismeasured.

    \begin{verbatim}
> x1 <- c(x1, 0.1)
> x2 <- c(x2, 0.8)
> y <- c(y, 6)
    \end{verbatim}

    Re-fit the lienar models from c-e using this new data. What effects does
    this new observation have on each of the models? In each model, is this
    observation an outlier? A high leverage point?  Both? Explain your answers
    and make suitable plots.
    \\

    \solution

    Solution.
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
    This problem relates to the QDA model, in which the obesrvations within
    each class are drawn from a normal distribution with a class specific mean
    vector and a class specific covariance matrix. We consider the simple case
    where \(p = 1\), there is only one feature. Suppose that we have \(K\)
    classes, and if an observation belongs to the \(kth\) class then \(X\)
    comes from a one-dimensional normal distribution, \(X \dist{N}(\mu_k,
    \sigma_k^2)\).  Recall that the density function for the one-dimensional
    normal distribution is given in Eq. 4.11 in the text.  Prove that in this
    case, the Bayes classifier is not linear. Argue that it is in fact
    quadract.
    \\

    \solution

    Solution.
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
    Suppose that you wish to predict whether a given stock will issue a
    dividend this year based on \(X\), last year's percent profit. We examine a
    large number of companies and discover that the mean value of \(X\) for
    companies is issued a dividend was \(\overline{X} = 10\), while the mean
    for those that didn't was \(\overline{X} = 0\). In addition, the variance
    of \(X\) for these two sets of companies was \(\sigma^2 = 36\). Finally,
    80\% of companies issued dividends.  Assuming that \(X\) follows a normal
    distribution, predict the probability that a company will issue a dividend
    this year given that its percentage profit was \(X = 4\) last year.
    \\

    \solution

    Solution.
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
    This question should be answered using the Weekly data set, which is part
    of the ISLR package. This data is similar in nature to the \textit{Smarket}
    data from this chapter's lab, except that it contains 1,089 weekly returns
    for 21 years, from the beginning of 1990 to the end of 2010.
    \\

    \part

    Produce some numerical and graphical summaries of the Weekly data. Do there
    appear to be any patterns?
    \\

    \solution

    Solution.
    \\

    \part

    Use the full data set to perform a logistic regression with
    \textit{Direction} as the response and the five lag variables plus
    \textit{Volume} as predictors. Use the summary function to print the
    results. Do any of the predictors appear to be statistically significant?
    If so, which ones?
    \\

    \solution

    Solution.
    \\

    \part

    Compute the confusion matrix and overall fraction of correct predictions.
    Explain what the confusion matrix is telling you about the types of
    mistakes made by logistic regression.
    \\

    \solution

    Solution.
    \\

    \part

    Now fit the logistic regression model using a training data period from
    1990 to 2008, with \textit{Lag2} as the only predictor. Compute the
    confusion matrix and the overall fraction of correct predictions for the
    held out data (that is, the data from 2009 and 2010).
    \\

    \solution

    Solution.
    \\

    \part

    Repeat (d) using LDA.
    \\

    \solution

    Solution.
    \\

    \part

    Repeat (d) using QDA.
    \\

    \solution

    Solution.
    \\

    \part

    Is it justified to use QDA? Use appropriate hypothesis test(s) we've seen
    in class.
    \\

    \solution

    Solution.
    \\

    \part

    Repeat (d) using KNN with \(K = 1\).
    \\

    \solution

    Solution.
    \\

    \part

    Which of these methods appears to provide the best results on this data?
    \\

    \solution

    Solution.
    \\

    \part

    Could you create a better classifier? How would you do this?
    \\

    \solution

    Solution.
\end{homeworkProblem}

\end{document}
