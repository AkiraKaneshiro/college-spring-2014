\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{subcaption}
\usepackage{float}

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\setlength\parindent{0pt}

\linespread{1.1}

\pagestyle{fancy}
\lhead{\hmwkAuthorName}
\chead{\hmwkClass\ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle}
\rhead{\firstxmark}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength{\floatsep}{100pt}

\newcommand{\enterProblemHeader}[1]{
    \nobreak\extramarks{}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
}

\newcommand{\exitProblemHeader}[1]{
    \nobreak\extramarks{Problem \arabic{#1} (continued)}{Problem \arabic{#1} continued on next page\ldots}\nobreak{}
    \stepcounter{#1}
    \nobreak\extramarks{Problem \arabic{#1}}{}\nobreak{}
}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}
\newcounter{homeworkProblemCounter}
\setcounter{homeworkProblemCounter}{1}
\nobreak\extramarks{Problem \arabic{homeworkProblemCounter}}{}\nobreak{}

\newenvironment{homeworkProblem}[1][]{
    \section{Problem \arabic{homeworkProblemCounter} \; \large{#1}}
    \setcounter{partCounter}{1}
    \enterProblemHeader{homeworkProblemCounter}
}{
    \exitProblemHeader{homeworkProblemCounter}
}

\newcommand{\hmwkTitle}{Homework\ \#3}
\newcommand{\hmwkDueDate}{March 28, 2014}
\newcommand{\hmwkClass}{ComS 573}
\newcommand{\hmwkClassTime}{10am}
\newcommand{\hmwkClassInstructor}{De Brabanter}
\newcommand{\hmwkAuthorName}{Josh Davis}

\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
    \normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate}\\
    \vspace{0.1in}\large{\textit{Professor\ \hmwkClassInstructor\ at\ \hmwkClassTime}}
    \vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}
\date{}

\newcommand{\deriv}[1]{\frac{\mathrm{d}}{\mathrm{d}x} (#1)}
\newcommand{\pderiv}[2]{\frac{\partial}{\partial #1} (#2)}
\newcommand{\dx}{\mathrm{d}x}
\newcommand{\solution}{\textbf{\large Solution}}

\newcommand{\E}{\mathrm{E}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Bias}{\mathrm{Bias}}
\newcommand{\Std}{\mathrm{Std}}
\newcommand{\N}{\mathcal{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Likelihood}{\mathcal{L}}
\newcommand{\dist}[1]{\sim \mathrm{#1}}
\newcommand{\pval}{\(p\)-value}
\newcommand{\tstat}{\(t\)-statistic}

\newcommand{\X}{{\bold X}}
\newcommand{\Y}{{\bold Y}}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

\begin{document}

<<echo=FALSE, warning=FALSE, message=FALSE>>=
library('MASS')

# For Best Subset Selection
library('leaps')

# For Ridge Regression
library('glmnet')

# For Bootstrapping
library(boot)
@

\maketitle

\pagebreak

\begin{homeworkProblem}
    From ISLR: Chapter 6, Problem 7.
    \\

    Suppose that \(Y_i = \beta_0 + \sum_{j = 1}^p x_{ij} \beta_j + e_i\) where
    \(e_1, \ldots, e_n\) are i.i.d. distributed from a \(\N(0, \sigma^2_e)\).
    \\

    \part

    Write out the likelihood for the data and show that it is equivalent to
    using ordinary least squares.
    \\

    \solution

    Often it is useful to calculate the statistical parameters, \(\theta\), of
    a model. However this can be hard to do given data from the model, \(X\).
    Written out, the probability of getting the data we got using the
    parameters given the data or \(\Pr[X \mid \theta]\).
    \\

    The idea behind the likelihood is that we want to determine the probability
    in the reverse and think about given the data that we got, what is most
    likely the values of the parameters, or \(\Likelihood(\theta \mid X)\).
    Putting this together we get:
    \[
        \Likelihood(\theta \mid X) = P(X \mid \theta)
    \]

    Given that we know these i.i.d. which means we can

    \part

    Assume the following prior for \(\beta\): \(\beta_1, \ldots, \beta_p\), are
    i.i.d. according to a Laplace distribution with mean zero and common scale
    parameter \(c\), i.e., \(h(\beta) = \frac{1}{2c} \exp \left(- \left\| \beta
    \right\| / c \right)\).
    \\

    Write out the posterior for \(\beta\) in this setting. Argue that the LASSO
    estimate is the mode for \(\beta\) i.e., the most likely value for
    \(\beta\), under this posterior distribution. Determine the value for the
    parameter \(\lambda\) in the LASSO cost function.
    \\

    \solution

    pg. 226

\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
    Suppose we estimate some statistics (e.g. median) based on a sample \(X\).
    \\

    \part

    Carefully describe how you might estimate the standard deviation of the
    median of the statistic.
    \\

    \solution

    This is the perfect situation in which we could leverage the bootstrap.
    The way we'd do this, is that we know we have a sample, \(X\). If we
    randomly sample some \(B\) number of elements \textit{with replacement},
    then we can determine a good estimate for a statistic of the population.
    \\

    Since we want to calculate the median of \(X\), we know that the median is
    given as \(\Pr[X < M] < 0.5\) and \(\Pr[X > M] > 0.5\). This is the value
    in which there is equal probability of being above and below it.
    \\

    \part

    Write R code that calculates the standard deviation of the median given a
    sample \(X\).
    \\

    \solution

<<>>=
# Load data & sample
lawstat <- read.table("lawstat.dat")

# Sample obvseration indices
s <- c(4,6,13,15,31,35,36,45,47,50,52,53,70,79,82)

# Given data of 15 observations
X <- lawstat[s,]
L <- length(X$GPA)


#
# Manual Bootstrap
#

# Bootstrap 4k times
B <- 4000

boot.custom <- function() {
    results <- rep(0, B)

    # Median of our sample, X
    median(X$GPA)

    # I choose you, Bootstrap!
    for (i in 1:B) {
        obs <- round(L * runif(L, 0, 1))
        sample <- X[obs,]
        results[i] <- median(sample$GPA)
    }

    sd(results)
}

boot.actual <- function () {
    # Calculate the actual value
    actual <- rep(0, B)
    L <- length(lawstat$GPA)

    for (i in 1:B) {
        obs <- round(L * runif(L, 0, 1))
        sample <- lawstat[obs,]
        actual[i] <- median(sample$GPA)
    }

    # Calculated vs actual
    sd(actual)
}

#
# Using Boot Library
#

boot.median <- function () {
    boot.fn <- function (data, indices) {
        sample <- X[indices,]
        result <- median(sample$GPA)
        result
    }

    results <- boot(data = X, statistic = boot.fn, R = B)
    results
}

# Show calculated
boot.custom()

# Show actual
boot.actual()

# Show calcualted vs actual using boot library
boot.median()
@
    \part

    Suppose you were interested in a \(100(1 - \alpha)\) (pointwise) confidence
    interval for the correlation coefficient of a sample of \(X\) and \(Y\)
    (the joint distribution of \(X\) and \(Y\) is not bivariate normal).
    Clearly explain and derive how you would do this? Write R code that
    calculates the 95\% confidence interval for the correlation coefficient in
    case of the lawstat.dat data.
    \\

    \solution

    Solution
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
    From ISLR: Chapter 6, Problem 11.
    \\

    Using the Boston Housing data set (in the MASS library) complete the following.
    \\

    \part

    Try out some of the regression methods explore in Chapter 6 of the
    textbook. These include best subset selection, the lasso, ridge regression,
    and PCR. Present and discuss results for the approaches that you consider.
    \\

    \solution

    \subsubsection{Best Subset Selection}

<<>>=
fit.full <- regsubsets(medv ~ ., Boston)
summary(fit.full)
@

    \subsubsection{Forward Stepwise Selection}

<<>>=
fit.full <- regsubsets(medv ~ ., Boston, method="forward")
summary(fit.full)
@

    \subsubsection{Backward Stepwise Selection}

<<>>=
fit.full <- regsubsets(medv ~ ., Boston, method="backward")
summary(fit.full)
@

    \subsubsection{LASSO}

    Solution.

    \subsubsection{Ridge Regression}

    Solution.

    \subsubsection{PCR}

    Solution.
    \\

    \part

    Propose a model (or a set of models) that seem to perform well on this data
    set, and justify your answer. Clearly explain what you will do.
    \\

    \solution

    Solution.
\end{homeworkProblem}

\pagebreak

\begin{homeworkProblem}
    Describe how you can efficiently solve the least squares linear system
    \((\X^T \X)\beta = \X^T \Y\) (i.e., by not calculating an interverse) where
    \(\X \in \R^{n \times p}\) has \(p\) linearly independent columns, \(\beta
    \in \R^p\) and \(\Y \in \R^{n \times 1}\)?
    \\

    \textit{Hint:} Think in terms of matrix decompositions (it's not SVD!). Use
    Wikipedia.
    \\

    \solution

    Solution.
\end{homeworkProblem}

\end{document}
